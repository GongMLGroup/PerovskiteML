[experiment]
name = "example_sweep"
seed = 42
local_save = false
verbose = 1
# 0: Silent, only critical errors
# 1: Warnings and above
# 2: Info and above
# 3: Debug and above

[logging]
enabled = true
name = "EXAMPLE-SWEEP"
project = "gongjiawei105/PVSK-ML"
api_token = "${NEPTUNE_API_TOKEN}"
group_tags = ["example"]
tags = ["xgboost", "sweep"]

[hyperparameters]
n_trials = 50
direction = "minimize"
study_name = "example_opt"


[data]
target_feature = "JV_default_PCE"
cache_dir = "data/expanded"
force_recompute = false

[pruning]
method = "chain_pruner"

[[pruning.steps]]
method = "feature_pruner"
sections = [
    "Reference information",
    "Cell definition",
    "Outdoor testing",
    "JV data",
]
features = [
    "Outdoor_time_start",
    "Outdoor_time_end"
]

[[pruning.steps]]
method = "breadth_pruner"
sparsity_threshold = { type = "float", low = 0, high = 1 }

[[pruning.steps]]
method = "depth_pruner"
layer_coverage = { type = "float", low = 0, high = 1 }


# ---------------------------------------------------------
# Data Preprocessing
# ------------------
#
# This creates a preprocessor pipeline.
# The order of the steps matters for the order
# they are computed in the pipeline.
# ---------------------------------------------------------

[[process.categorical]]
type = "encode"
method = "ordinal"
handle_unknown = 'use_encoded_value'
unknown_value = -1
# Additional kwargs can be included. scikit-learn has documentation for these.
# https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html

[[process.numerical]]
type = "other"
method = "passthrough"

[model]
model_type = "xgboost"
n_estimators = { type = "int", low = 100, high = 1000}
max_depth = { type = "int", low = 3, high = 12 }
learning_rate = { type = "float", low = 0.01, high = 0.3 }
subsample = { type = "float", low = 0.5, high = 1.0}
min_child_weight = { type = "int", low = 1, high = 10}
colsample_bytree = { type = "float", low = 0.5, high = 1.0}
gamma = { type = "float", low = 0.0, high = 0.5}
verbose = false

